
# ğŸ” Cybersecurity Chatbot using LangChain + Gemini

This is an intelligent chatbot designed to answer technical cybersecurity-related questions using trusted sources like NIST and ENISA reports. It leverages **Google's Gemini-Pro model**, **LangChain**, and **FAISS** for Retrieval-Augmented Generation (RAG), with an easy-to-use interface built in **Streamlit**.

---

## ğŸš€ Features

- Ask cybersecurity questions based on real-world reports and standards.
- Uses Retrieval-Augmented Generation (RAG) for accurate, grounded answers.
- Embeds documents using Google's `models/embedding-001`.
- Responses generated using the `gemini-pro` chat model.
- Clean and interactive UI built with Streamlit.

---

## ğŸ“ Project Structure

```
LLM Proj1/
â”‚
â”œâ”€â”€ app.py                  ğŸ‘‰ Main Streamlit app to run the chatbot
â”œâ”€â”€ rag.py                  ğŸ‘‰ Builds and queries the vector database using FAISS
â”œâ”€â”€ llm.py                  ğŸ‘‰ Connects to Gemini-Pro using LangChain
â”œâ”€â”€ test.py                 ğŸ‘‰ (Optional) Used for testing single queries
â”œâ”€â”€ docs/                   ğŸ‘‰ Folder containing cybersecurity PDFs (NIST, ENISA, etc.)
â”œâ”€â”€ text_files/             ğŸ‘‰ Converted text files from the PDFs
â”œâ”€â”€ faiss_index/            ğŸ‘‰ Stored FAISS index for document search
â”œâ”€â”€ requirements.txt        ğŸ‘‰ All Python dependencies
â””â”€â”€ README.md               ğŸ‘‰ You're here!
```

---

## ğŸ§  Models Used

| Purpose          | Model Name               | Description                                |
|------------------|--------------------------|--------------------------------------------|
| Embedding Model  | `models/embedding-001`   | Converts docs & queries into vector form   |
| Chat Model (LLM) | `gemini-pro`             | Generates final response with LangChain    |

---

## ğŸ“š Dataset

Documents used include:
- NIST Special Publications (SP 800-53, SP 800-37, etc.)
- ENISA Threat Landscape Reports

These are stored in the `/docs` folder and processed into chunks using LangChain.

---

## ğŸ› ï¸ How It Works

1. **Document Ingestion:**
   - Cybersecurity PDFs are converted to text using LangChain loaders.
   - Text is split into manageable chunks.

2. **Embeddings:**
   - Each chunk is embedded using Googleâ€™s `models/embedding-001`.

3. **Vector Store:**
   - FAISS is used to store embeddings and enable similarity search.

4. **User Query:**
   - A user's question is embedded and matched to the most similar chunks.
   - These chunks are passed to `gemini-pro` via LangChain for answer generation.

---

## â–¶ï¸ Running the App

### 1. ğŸ”§ Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. ğŸ”‘ Set API Key
In your terminal:
```bash
export GOOGLE_API_KEY="your_gemini_api_key_here"
```

### 3. ğŸ§  Build Vector Index (Only once)
```bash
python rag.py
```

### 4. ğŸš€ Launch the Chatbot
```bash
streamlit run app.py
```

---

## ğŸ’¬ Sample Questions to Try

- What are the five functions of the NIST Cybersecurity Framework?
- What does ENISA say about ransomware attacks?
- How does NIST define risk assessment and risk management?
- What steps should be taken for incident response according to NIST?

---

## ğŸ§ª Tech Stack

- **LangChain** â€“ Framework for LLM applications
- **Google Gemini Pro** â€“ LLM used for generating answers
- **models/embedding-001** â€“ Embedding model for semantic similarity
- **FAISS** â€“ Vector database for fast similarity search
- **Streamlit** â€“ Interactive UI
- **Python** â€“ Backend programming

---

## ğŸ“Œ Notes

- Make sure to convert new PDFs to `.txt` and run `rag.py` again if documents are updated.
- You can test individual questions using `test.py` before deploying to the app.

---

## âœ¨ Future Improvements

- Add chat history
- Include feedback mechanism
- Connect more cybersecurity datasets or real-time threat feeds

---

## ğŸ§‘â€ğŸ’» Author

Developed by [Your Name]

---

## ğŸ›¡ï¸ License

This project is for educational/demo purposes. Review NIST/ENISA licensing for document reuse.
